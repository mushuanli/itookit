
/**
 * @file #common/configData.js
 * @description Single source of truth for LLM provider static metadata.
 * This includes default URLs, recommended models, etc., to be consumed
 * by both the core library and the settings UI.
 */

import { Batches } from 'openai/resources.js';

export const PROTECTED_TAGS = ['default'];
export const PROTECTED_AGENT_IDS = ['default', 'default-temp'];

export const LLM_PROVIDER_DEFAULTS = {
    openai: {
        name: "OpenAI",
        baseURL: 'https://api.openai.com/v1/chat/completions',
        models: [
            { id: 'gpt-5-pro', name: 'GPT-5 Pro' },
            { id: 'gpt-5', name: 'GPT-5' },
            { id: 'gpt-5-mini', name: 'GPT-5 Mini' },
            { id: 'gpt-5-codex', name: 'GPT-5 CodeX' },
            { id: 'gpt-4.1', name: 'GPT-4.1' },
        ]
    },
    anthropic: {
        name: "Anthropic (Claude)",
        baseURL: 'https://api.anthropic.com/v1/messages',
        models: [
            { id: 'claude-opus-4-1-20250805', name: 'Claude Opus 4.1' },
            { id: 'claude-opus-4-20250514', name: 'Claude Opus 4' },
            { id: 'claude-sonnet-4-5-20250929', name: 'Claude Sonnet 4.5' },
            { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4' },
            { id: 'claude-3-7-sonnet-latest', name: 'Claude Sonnet 3.7 (Latest)' },
            { id: 'claude-3-7-sonnet-20250219', name: 'Claude Sonnet 3.7' },
        ]
    },
    gemini: {
        name: "Google Gemini",
        // Gemini's URL is model-specific, so we provide a template or base.
        // The provider logic will handle appending the model.
        baseURL: `https://generativelanguage.googleapis.com/v1beta/models`,
        models: [
            { id: 'gemini-2.5-pro', name: 'Gemini 2.5 Pro' },
            { id: 'gemini-2.5-flash', name: 'Gemini 2.5 Flash' },
            { id: 'gemini-pro', name: 'Gemini Pro' },
        ]
    },
    deepseek: {
        name: "DeepSeek",
        baseURL: 'https://api.deepseek.com/v1/chat/completions',
        models: [
            { id: 'deepseek-chat', name: 'DeepSeek Chat' },
            { id: 'deepseek-reasoner', name: 'DeepSeek Reasoner' },
            //{ id: 'deepseek-v3.2-exp', name: 'DeepSeek V3.2 Exp' },
            //{ id: 'deepseek-v3.1-terminus', name: 'DeepSeek V3.1 Terminus' },
            //{ id: 'deepseek-coder', name: 'DeepSeek Coder' },
        ]
    },
    openrouter: {
        name: "OpenRouter",
        baseURL: 'https://openrouter.ai/api/v1/chat/completions',
        models: [
            // --- Auto Router ---
            { id: 'openrouter/auto', name: 'Auto (Best Model)' },
            
            // --- OpenAI Models via OpenRouter ---
            { id: 'openai/gpt-5-pro', name: 'OpenAI: GPT-5 Pro' },
            { id: 'openai/gpt-5-codex', name: 'OpenAI: GPT-5 Codex' },
            { id: 'openai/gpt-5-mini', name: 'OpenAI: GPT-5 Mini' },
            
            // --- Anthropic Models via OpenRouter ---
            { id: 'anthropic/claude-sonnet-4.5', name: 'Anthropic: Claude Sonnet 4.5' },
            { id: 'anthropic/claude-opus-4.1', name: 'Anthropic: Claude Opus 4.1' },
            
            // --- Google Models via OpenRouter ---
            { id: 'google/gemini-2.5-pro', name: 'Google: Gemini 2.5 Pro' },
            { id: 'google/gemini-2.5-flash', name: 'Google: Gemini 2.5 Flash' },

            // --- Other Top Models from the List ---
            { id: 'meta-llama/llama-4-maverick', name: 'Meta: Llama 4 Maverick' },
            { id: 'nousresearch/hermes-4-405b', name: 'Nous: Hermes 4 405B' },
            { id: 'mistralai/mistral-large-2411', name: 'Mistral: Mistral Large 2411' },
            { id: 'z-ai/glm-4.6', name: 'Z.AI: GLM 4.6' },
            { id: 'x-ai/grok-4', name: 'xAI: Grok 4' }
        ]
    },
    custom_openai_compatible: {
        name: "Custom (OpenAI Compatible)",
        baseURL: '', // User must provide this
        models: [] // User must add their own models
    }
};


// +++ æ–°å¢: é»˜è®¤å€¼å®šä¹‰ +++

export const LLM_DEFAULT_ID = 'default';
export const LLM_TEMP_DEFAULT_ID = 'default-temp';
const LLM_DEFAULT_NAME = 'é»˜è®¤';
const LLM_TEMP_DEFAULT_NAME = 'ä¸´æ—¶';


/**
 * å†³å®šé»˜è®¤ä½¿ç”¨å“ªä¸ª provider çš„è¾…åŠ©å‡½æ•°, å¯ä»¥ä¿®æ”¹è¿™é‡Œæ”¹å˜å®‰è£…é»˜è®¤å€¼
 * @returns {string}
 */
const getDefaultProviderKey = () => {
    const providers = Object.keys(LLM_PROVIDER_DEFAULTS);
    // ä¼˜å…ˆä½¿ç”¨ 'openai'ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªï¼Œæœ€åå›é€€åˆ°è‡ªå®šä¹‰ç±»å‹
    return providers.includes('openai') ? 'openai' : (providers[0] || 'custom_openai_compatible');
};

const defaultProviderKey = getDefaultProviderKey();
const defaultProviderConfig = LLM_PROVIDER_DEFAULTS[defaultProviderKey];


/**
 * @type {import('../configManager/shared/types.js').LLMProviderConnection}
 * é»˜è®¤è¿æ¥çš„æ¨¡æ¿ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¼šè¢«åˆ›å»ºã€‚
 */
export const LLM_DEFAULT_CONNECTION = {
    id: LLM_DEFAULT_ID,
    name: LLM_DEFAULT_NAME,
    provider: defaultProviderKey,
    apiKey: '',
    baseURL: defaultProviderConfig.baseURL,
    // å®‰å…¨åœ°å¤åˆ¶æ¨¡å‹æ•°ç»„ï¼Œé˜²æ­¢æ„å¤–ä¿®æ”¹åŸå§‹å®šä¹‰
    availableModels: defaultProviderConfig.models ? [...defaultProviderConfig.models] : []
};

/**
 * @type {Array<import('../configManager/shared/types.js').LLMAgentDefinition>}
 * é»˜è®¤æ™ºèƒ½ä½“çš„æ¨¡æ¿æ•°ç»„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¼šè¢«åˆ›å»ºã€‚
 */
export const LLM_DEFAULT_AGENTS = [
    {
        id: LLM_DEFAULT_ID,
        name: LLM_DEFAULT_NAME,
        icon: 'ğŸ¤–',
        description: 'ç³»ç»Ÿé»˜è®¤æ™ºèƒ½ä½“',
        tags: ['default'],
        config: {
            connectionId: LLM_DEFAULT_ID,
            modelName: (LLM_DEFAULT_CONNECTION.availableModels?.[0]?.id) || "",
            systemPrompt: "You are a helpful assistant."
        },
        interface: {
            inputs: [{ name: "prompt", type: "string" }],
            outputs: [{ name: "response", type: "string" }]
        }
    },
    {
        id: LLM_TEMP_DEFAULT_ID,
        name: LLM_TEMP_DEFAULT_NAME,
        icon: 'âš¡ï¸',
        description: 'ä¸€æ¬¡æ€§é—®ç­”ã€‚',
        tags: ['default'],
        maxHistoryLength: 0,
        config: {
            connectionId: LLM_DEFAULT_ID,
            modelName: (LLM_DEFAULT_CONNECTION.availableModels?.[0]?.id) || "",
            systemPrompt: "You are a helpful assistant. Answer the user's current prompt concisely and accurately, without referring to any past conversation history."
        },
        interface: {
            inputs: [{ name: "prompt", type: "string" }],
            outputs: [{ name: "response", type: "string" }]
        }
    }
];

export const MDX_EDITOR_GUIDE_TEMPLATE = `# æ¬¢è¿ä½¿ç”¨ MDxEditorï¼

è¿™æ˜¯ä¸€ä¸ªæ–°æ–‡æ¡£ã€‚è¿™é‡Œæœ‰ä¸€äº›å…¥é—¨æç¤ºï¼Œå¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹ï¼š

## æ ¸å¿ƒåŠŸèƒ½

- **æ ¼å¼åŒ–æ–‡æœ¬**: é€‰ä¸­ä¸‹é¢çš„æ–‡å­—ï¼Œç„¶åä½¿ç”¨é¡¶éƒ¨å·¥å…·æ çš„ **B** æŒ‰é’®å°†å…¶åŠ ç²—ã€‚
> è¿™æ˜¯éœ€è¦è¢«åŠ ç²—çš„ç¤ºä¾‹æ–‡æœ¬ã€‚

- **åˆ›å»ºä»»åŠ¡åˆ—è¡¨**:
- [ ] ä½¿ç”¨å·¥å…·æ çš„å¤é€‰æ¡†æŒ‰é’®åˆ›å»ºä»»åŠ¡ã€‚
- [ ] åœ¨é¢„è§ˆæ¨¡å¼ä¸‹ï¼Œä½ å¯ä»¥ç›´æ¥ç‚¹å‡»å¤é€‰æ¡†æ¥å®Œæˆä»»åŠ¡ã€‚

## äº¤äº’å¼å…ƒç´ 

- **Cloze (å¡«ç©º)**: è¿™æ˜¯å­¦ä¹ å’Œè®°å¿†çš„åˆ©å™¨ã€‚é€‰ä¸­â€œåç››é¡¿â€å¹¶ç‚¹å‡»å·¥å…·æ ä¸Šçš„ \`[-]\` æŒ‰é’®æ¥åˆ›å»ºä¸€ä¸ªå¡«ç©ºã€‚
> ç¾å›½çš„ç¬¬ä¸€ä»»æ€»ç»Ÿæ˜¯ä¹”æ²»Â·åç››é¡¿ã€‚

- **å¯æŠ˜å åŒºåŸŸ**: å¯¹äºå†—é•¿çš„å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨æŠ˜å å—ã€‚
::> ç‚¹å‡»è¿™é‡Œå±•å¼€æŸ¥çœ‹è¯¦æƒ…
    è¿™é‡Œæ˜¯éšè—çš„è¯¦ç»†å†…å®¹ã€‚
    ä½ å¯ä»¥åœ¨è¿™é‡Œå†™å…¥ä»»ä½• Markdown æ ¼å¼çš„å†…å®¹ï¼ŒåŒ…æ‹¬åˆ—è¡¨ã€ä»£ç å—ç­‰ã€‚

\`\`\`js
console.log('hello world!');
\`\`\`
---

ç°åœ¨ï¼Œåˆ é™¤è¿™äº›æç¤ºï¼Œå¼€å§‹ä½ çš„åˆ›ä½œå§ï¼
`;
